{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKrbJLWDZu3wliz6EApWTg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/435wldms/essa/blob/main/20231109_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "562-579"
      ],
      "metadata": {
        "id": "YRY-eY5c86Fh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추천 시스템"
      ],
      "metadata": {
        "id": "qYdLO8FN87Rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**01 추천 시스템의 개요와 배경**\n",
        "* 추천시스템은 사용자 자신도 좋아하는지 몰랐던 취향을 시스템이 발견하고 그에 맞는 콘텐츠를 추천해주기 때문에 사용자가 해당 사이트를 더 강하게 신뢰하게 되어 더 많은 추천 콘텐츠를 선택하고, 더 정확하고 다양한 결과를 얻을 수 있는 선순환 시스템을 구축하게 됨."
      ],
      "metadata": {
        "id": "J-vSKG_69Cso"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**온라인 스토어의 필수 요소, 추천 시스템**\n",
        "* 너무 많은 상품 이미지, 카테고리, 메뉴 구성등으로 어려움을 겪는 사용자들에게 추천 시스템은 좋은 역할을 함\n",
        "* 여러 데이터를 기반으로 추천 시스템은 친숙한 문구를 통해 사용자가 상품을 구매하도록 유혹\n"
      ],
      "metadata": {
        "id": "VcAQl7Nu-XEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**추천 시스템의 유형**\n",
        "* 추천 시스템의 종류: 콘텐츠 기반 필터링,협업 필터링, 잠재 요인 협업 필터링\n",
        "* 초창기에는 콘텐츠 기반, 최근접 이웃 기반 협업 필터링이 주로 사용되었지만, 추천 시스템 경연 대회에서 행렬 분해 기법을 이용한 잠재 요인 협업 필터링 방식이 우승하면서 대부분 잠재요인 협업 필터링 기반 추천 시스템 적용\n",
        "* 서비스하는 아이템에 따라 다양한 방식을 사용하지만 요즘에는 개인화 특성을 좀 더 강화하기 위해서 하이브리드 형식으로 콘텐츠 기반과 협업 기반을 적절히 결합해 사용하는 경우가 많음"
      ],
      "metadata": {
        "id": "SJrRL964_NfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**02 콘텐츠 기반 필터링 추천 시스템**\n",
        "* 사용자가 특정한 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 다른 아이템을 추천하는 방식\n"
      ],
      "metadata": {
        "id": "HF2Ftlqd_8Pv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**03 최근접 이웃 협업 필터링**\n",
        "* 친구에게 물어보는 것과 유사한 방식으로 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식만을 기반으로 추천을 수행하는 것이 협업 필터링 방식\n",
        "* 주요 목표는 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 예측 평가하는 것\n",
        "* 협업 필터링 기반 추천 시스템: 최근접 이웃 방식, 잠재 요인 방식 (평점 행렬 데이터에만 의지해 추천 수행) -> 행은 개별 사용자, 열은 개별 아이템, 칸의 수치는 평점\n",
        "* 원하는 정리된 행렬이 아니면 pivot_table()과 같은 함수를 이용해 사용자-아이템 평점 행렬 형태로 변경해야 함\n",
        "* 사용자-아이템 평점 행렬은 많은 아이템을 열로 가지는 다차원 행렬, 평점을 매기는 경우가 많지 않으므로 희소 행렬인 특징\n",
        "* 최근접 이웃 협업 필터링 (=메모리 협업 필터링) - 사용자 기반과 아이템 기반으로 구분\n",
        "* 사용자 기반 최근접 이웃 방식은 '특정 사용자와 유사한 다른 사용자를 top-n으로 선정해' 이 top-n 사용자가 좋아하는 아이템을 추천하는 방식\n",
        "* 아이템 기반 최근접 이웃 방식은 아이템이 가지는 속성과는 상관없이, 사용자들이 아이템을 좋아하는지/싫어하는지 '평가 척도가 유사한' 아이템을 추천하는 알고리즘\n",
        "* 일반적으로 사용자 기반보다는 아이템 기반 협업 필터링이 정확도가 더 높음. (비슷한 영화를 좋아한다고 해서 사람들의 취향이 비슷하다고 판단하기는 어려운 경우가 많기 때문)\n",
        "* 텍스트 분석에서 소개된 유사도 측정 방법인 코사인 유사도를 가장 많이 사용함 (피처 벡터화된 텍스트 데이터와 동일하게 다차원 희소 행렬의 특징을 가지기 때문)"
      ],
      "metadata": {
        "id": "3fzVvVRfCOfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**04 잠재 요인 협업 필터링**\n",
        "* 사용자-아이템 평점 매트릭스 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법\n",
        "* 행렬 분해: 대규모 다차원 행렬을 svd와 같은 차원 감소 기법으로 분해하는 과정에서 잠재 요인을 추출\n",
        "* 잠재 요인 협업 필터링은 사용자-아이템 평점 행렬 데이터만을 이용해 '잠재 요인'을 이끌어내는 것, 잠재 요인을 기반으로 다차원 희소행렬을 저차원 밀집 행렬의 사용자-잠재요인 / 아이템-잠재요인행렬의 전치행렬로 분해할 수 있음\n",
        "* 분해된 행렬의 내적을 통해 새로운 예측 사용자-아이템 평점 행렬 데이터를 만들어 아직 평점을 부여하지 않은 아이템에 대한 예측 평점 생성\n"
      ],
      "metadata": {
        "id": "IMLOsvoaHDwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**행렬 분해의 이해**\n",
        "* 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법, 대표적으로 svd, nmf 등\n",
        "* m개의 사용자 n개의 아이템을 가진 평점 행렬 R을 K차원인 잠재요인을 이용해 MxK(P), KxN(Q)의 행렬로 분해\n",
        "* R(u,i) = p(u) * q(i)t -> p의 u행, q의 i행 사용자의 벡터  => 방식으로 계산하여 값을 구하고 예측도 수행 가능\n",
        "* 행렬 분해는 주로 svd 방식 사용 but null이 없어야 함 -> 확률적 경사 하강법이나 als 방식 이용"
      ],
      "metadata": {
        "id": "Hkd8vwheOE4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**확률적 경사 하강법을 이용한 행렬 분해**\n",
        "* p와 q행렬로 계산된 예측 r 행렬 값이 실제 r 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해 p와 q를 유추해내는 것\n",
        "* p와 q를 임의의 값을 가진 행렬로 설정 -> p * q(t)를 계산해 r행렬을 계산하고 실제 행렬과의 오류 값 계산 -> 이 값을 최소화하기 위해 적절한 값으로 각각 업데이트를 반복\n",
        "* 과적합을 피하기 위해 규제를 반영한 비용 함수를 적용"
      ],
      "metadata": {
        "id": "1XLwHQs-RWbp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OpwqYtsm8Qlz"
      },
      "outputs": [],
      "source": [
        "# SGD를 이용해 행렬 분해를 수행하는 과정\n",
        "import numpy as np\n",
        "\n",
        "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재 요인 차원 K는 3으로 설정.\n",
        "R = np.array([[4, np.NaN,np.NaN,2,np.NaN ],\n",
        "              [np.NaN, 5, np.NaN, 3,1],\n",
        "              [np.NaN,np.NaN,3,4,4],\n",
        "              [5,2,1,2,np.NaN]])\n",
        "num_users, num_items = R.shape\n",
        "K=3\n",
        "\n",
        "# P와 Q 행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력합니다.\n",
        "np.random.seed(1)\n",
        "P = np.random.normal(scale=1./K, size=(num_users,K))\n",
        "Q = np.random.normal(scale=1./K, size=(num_items,K))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 실제 R 행렬과 예측 행렬의 오차를 구하는 get_rmse() 함수 생성\n",
        "# null이 아닌 행렬 값의 위치 인덱스를 추출해 이 인덱스에 있는 실제 행렬 값과 예측 행렬 값의 RMSE 계산\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R,P,Q,non_zeros):\n",
        "  error=0\n",
        "  # 두 개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
        "  full_pred_matrix = np.dot(P,Q.T)\n",
        "\n",
        "  # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출해 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
        "  x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
        "  y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
        "  R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
        "  full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
        "  mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "  rmse = np.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "CNYq8J4GVY-1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SGD 기반으로 행렬 분해 수행\n",
        "# R>0인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장.\n",
        "non_zeros = [(i,j,R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j]>0]\n",
        "\n",
        "steps=1000\n",
        "learning_rate=0.01\n",
        "r_lambda=0.01\n",
        "\n",
        "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트.\n",
        "for step in range(steps):\n",
        "  for i, j, r in non_zeros:\n",
        "    # 실제 값과 예측 값 차이인 오류 값 구함\n",
        "    eij = r - np.dot(P[i,:], Q[j,:].T)\n",
        "    # Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i,:] = P[i,:] + learning_rate*(eij*Q[j,:]- r_lambda*P[i,:])\n",
        "    Q[j,:] = Q[j,:] + learning_rate*(eij*P[i,:]- r_lambda*Q[j,:])\n",
        "    rmse = get_rmse(R,P,Q,non_zeros)\n",
        "    if (step%50) ==0:\n",
        "      print('### iteration step:', step, 'rmse:',rmse)\n"
      ],
      "metadata": {
        "id": "mZc123lAY_Mm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71f7a77-e2b8-4db7-8dbd-1dfef71cc431"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### iteration step: 0 rmse: 3.2475255402584495\n",
            "### iteration step: 0 rmse: 3.2465908465596782\n",
            "### iteration step: 0 rmse: 3.240001170538425\n",
            "### iteration step: 0 rmse: 3.2381485790985485\n",
            "### iteration step: 0 rmse: 3.2383355624029324\n",
            "### iteration step: 0 rmse: 3.237066663018253\n",
            "### iteration step: 0 rmse: 3.235237278782524\n",
            "### iteration step: 0 rmse: 3.2334055187092163\n",
            "### iteration step: 0 rmse: 3.228120562324444\n",
            "### iteration step: 0 rmse: 3.22631720731668\n",
            "### iteration step: 0 rmse: 3.226425162809075\n",
            "### iteration step: 0 rmse: 3.225031693566006\n",
            "### iteration step: 50 rmse: 0.492114962541484\n",
            "### iteration step: 50 rmse: 0.49188671936595735\n",
            "### iteration step: 50 rmse: 0.4908767627014268\n",
            "### iteration step: 50 rmse: 0.490706148990846\n",
            "### iteration step: 50 rmse: 0.49080798389226865\n",
            "### iteration step: 50 rmse: 0.4901647116343035\n",
            "### iteration step: 50 rmse: 0.49024508668575006\n",
            "### iteration step: 50 rmse: 0.489756757805949\n",
            "### iteration step: 50 rmse: 0.48218311207525344\n",
            "### iteration step: 50 rmse: 0.4811970645881633\n",
            "### iteration step: 50 rmse: 0.48081064659815753\n",
            "### iteration step: 50 rmse: 0.47974466801926996\n",
            "### iteration step: 100 rmse: 0.16194061268842533\n",
            "### iteration step: 100 rmse: 0.16166562699344944\n",
            "### iteration step: 100 rmse: 0.16161141200643958\n",
            "### iteration step: 100 rmse: 0.16116356114982758\n",
            "### iteration step: 100 rmse: 0.16118459890224787\n",
            "### iteration step: 100 rmse: 0.1611576535414587\n",
            "### iteration step: 100 rmse: 0.16074062074907097\n",
            "### iteration step: 100 rmse: 0.1607870555862092\n",
            "### iteration step: 100 rmse: 0.16012047574106844\n",
            "### iteration step: 100 rmse: 0.16000216979571713\n",
            "### iteration step: 100 rmse: 0.15977861518477568\n",
            "### iteration step: 100 rmse: 0.15928672995049395\n",
            "### iteration step: 150 rmse: 0.07848601015141998\n",
            "### iteration step: 150 rmse: 0.07848079177619763\n",
            "### iteration step: 150 rmse: 0.0784719892990815\n",
            "### iteration step: 150 rmse: 0.07818883872608226\n",
            "### iteration step: 150 rmse: 0.0782281051577437\n",
            "### iteration step: 150 rmse: 0.07826580911164163\n",
            "### iteration step: 150 rmse: 0.07793327320473388\n",
            "### iteration step: 150 rmse: 0.0779743392550697\n",
            "### iteration step: 150 rmse: 0.07765182173568554\n",
            "### iteration step: 150 rmse: 0.07766626272528494\n",
            "### iteration step: 150 rmse: 0.0776647437457732\n",
            "### iteration step: 150 rmse: 0.07755208594596055\n",
            "### iteration step: 200 rmse: 0.045859319390486174\n",
            "### iteration step: 200 rmse: 0.04595201456054542\n",
            "### iteration step: 200 rmse: 0.04593818530380855\n",
            "### iteration step: 200 rmse: 0.04571925476884171\n",
            "### iteration step: 200 rmse: 0.045773362449762926\n",
            "### iteration step: 200 rmse: 0.04583324313321955\n",
            "### iteration step: 200 rmse: 0.04554336987382356\n",
            "### iteration step: 200 rmse: 0.04556733796254387\n",
            "### iteration step: 200 rmse: 0.04533114677976217\n",
            "### iteration step: 200 rmse: 0.04535800601049744\n",
            "### iteration step: 200 rmse: 0.04536046271008461\n",
            "### iteration step: 200 rmse: 0.04547016957963867\n",
            "### iteration step: 250 rmse: 0.030932377782945535\n",
            "### iteration step: 250 rmse: 0.03106556319026272\n",
            "### iteration step: 250 rmse: 0.031029680236964705\n",
            "### iteration step: 250 rmse: 0.030850452213331884\n",
            "### iteration step: 250 rmse: 0.030920977364975646\n",
            "### iteration step: 250 rmse: 0.03098581032875781\n",
            "### iteration step: 250 rmse: 0.030715238635107337\n",
            "### iteration step: 250 rmse: 0.030724131713940422\n",
            "### iteration step: 250 rmse: 0.030500713481216805\n",
            "### iteration step: 250 rmse: 0.030543488996828308\n",
            "### iteration step: 250 rmse: 0.030546149280102443\n",
            "### iteration step: 250 rmse: 0.030756357153356218\n",
            "### iteration step: 300 rmse: 0.023700921067176323\n",
            "### iteration step: 300 rmse: 0.02384764270710228\n",
            "### iteration step: 300 rmse: 0.023783826884411885\n",
            "### iteration step: 300 rmse: 0.02363407367817049\n",
            "### iteration step: 300 rmse: 0.02371977932294295\n",
            "### iteration step: 300 rmse: 0.023779296626743093\n",
            "### iteration step: 300 rmse: 0.02352363835476227\n",
            "### iteration step: 300 rmse: 0.023522032118347563\n",
            "### iteration step: 300 rmse: 0.023282850114225918\n",
            "### iteration step: 300 rmse: 0.023348382380318916\n",
            "### iteration step: 300 rmse: 0.02336857260102411\n",
            "### iteration step: 300 rmse: 0.023619009646156073\n",
            "### iteration step: 350 rmse: 0.02021788686228754\n",
            "### iteration step: 350 rmse: 0.020363417196870737\n",
            "### iteration step: 350 rmse: 0.02027498060491399\n",
            "### iteration step: 350 rmse: 0.020148040838373238\n",
            "### iteration step: 350 rmse: 0.02024476781930582\n",
            "### iteration step: 350 rmse: 0.020294129665721673\n",
            "### iteration step: 350 rmse: 0.020054451246922195\n",
            "### iteration step: 350 rmse: 0.02004616515150986\n",
            "### iteration step: 350 rmse: 0.019785450754631933\n",
            "### iteration step: 350 rmse: 0.019872163671029952\n",
            "### iteration step: 350 rmse: 0.019913056935359656\n",
            "### iteration step: 350 rmse: 0.020175740244585787\n",
            "### iteration step: 400 rmse: 0.018555306884096033\n",
            "### iteration step: 400 rmse: 0.018693172278321794\n",
            "### iteration step: 400 rmse: 0.018587273017947326\n",
            "### iteration step: 400 rmse: 0.018476868489610204\n",
            "### iteration step: 400 rmse: 0.018580228034010524\n",
            "### iteration step: 400 rmse: 0.018619459147895458\n",
            "### iteration step: 400 rmse: 0.018395150344702304\n",
            "### iteration step: 400 rmse: 0.018382815535496345\n",
            "### iteration step: 400 rmse: 0.018104487212290434\n",
            "### iteration step: 400 rmse: 0.018206500521417007\n",
            "### iteration step: 400 rmse: 0.01826325414603731\n",
            "### iteration step: 400 rmse: 0.01852721694884619\n",
            "### iteration step: 450 rmse: 0.017749125388039924\n",
            "### iteration step: 450 rmse: 0.01787799283775714\n",
            "### iteration step: 450 rmse: 0.017760993203808688\n",
            "### iteration step: 450 rmse: 0.017661712140436794\n",
            "### iteration step: 450 rmse: 0.01776873713301934\n",
            "### iteration step: 450 rmse: 0.017800066274960766\n",
            "### iteration step: 450 rmse: 0.017588398454789368\n",
            "### iteration step: 450 rmse: 0.017573576389943148\n",
            "### iteration step: 450 rmse: 0.017282872941760816\n",
            "### iteration step: 450 rmse: 0.017394659183730638\n",
            "### iteration step: 450 rmse: 0.017461670173759512\n",
            "### iteration step: 450 rmse: 0.01772417292263913\n",
            "### iteration step: 500 rmse: 0.017342489071125986\n",
            "### iteration step: 500 rmse: 0.017463195099101516\n",
            "### iteration step: 500 rmse: 0.017339368559432536\n",
            "### iteration step: 500 rmse: 0.01724729986303076\n",
            "### iteration step: 500 rmse: 0.01735635737519613\n",
            "### iteration step: 500 rmse: 0.0173821727449377\n",
            "### iteration step: 500 rmse: 0.017179997816739904\n",
            "### iteration step: 500 rmse: 0.017163548292492503\n",
            "### iteration step: 500 rmse: 0.016864394575987648\n",
            "### iteration step: 500 rmse: 0.016982189554233695\n",
            "### iteration step: 500 rmse: 0.017055459117684496\n",
            "### iteration step: 500 rmse: 0.017316621231486886\n",
            "### iteration step: 550 rmse: 0.01712517021043722\n",
            "### iteration step: 550 rmse: 0.017239088972313413\n",
            "### iteration step: 550 rmse: 0.017111004091682435\n",
            "### iteration step: 550 rmse: 0.017023627587490334\n",
            "### iteration step: 550 rmse: 0.01713388187564012\n",
            "### iteration step: 550 rmse: 0.01715601919034613\n",
            "### iteration step: 550 rmse: 0.016960718012420606\n",
            "### iteration step: 550 rmse: 0.016943117137424267\n",
            "### iteration step: 550 rmse: 0.016638084823766382\n",
            "### iteration step: 550 rmse: 0.016759615321581895\n",
            "### iteration step: 550 rmse: 0.01683668886149307\n",
            "### iteration step: 550 rmse: 0.017097144989823006\n",
            "### iteration step: 600 rmse: 0.016999555364021146\n",
            "### iteration step: 600 rmse: 0.017107988623161197\n",
            "### iteration step: 600 rmse: 0.01697712541287044\n",
            "### iteration step: 600 rmse: 0.01689291588773487\n",
            "### iteration step: 600 rmse: 0.017003942143965063\n",
            "### iteration step: 600 rmse: 0.017023648404998704\n",
            "### iteration step: 600 rmse: 0.016833301912645898\n",
            "### iteration step: 600 rmse: 0.016814828044551908\n",
            "### iteration step: 600 rmse: 0.016505574264468404\n",
            "### iteration step: 600 rmse: 0.016629524842347324\n",
            "### iteration step: 600 rmse: 0.016708971314448352\n",
            "### iteration step: 600 rmse: 0.016969184399783923\n",
            "### iteration step: 650 rmse: 0.016918974581069533\n",
            "### iteration step: 650 rmse: 0.01702299834808739\n",
            "### iteration step: 650 rmse: 0.016890196341032282\n",
            "### iteration step: 650 rmse: 0.016808261987279537\n",
            "### iteration step: 650 rmse: 0.016919840297588532\n",
            "### iteration step: 650 rmse: 0.016937919964934173\n",
            "### iteration step: 650 rmse: 0.016751188214482397\n",
            "### iteration step: 650 rmse: 0.016732016001539864\n",
            "### iteration step: 650 rmse: 0.01641963202055113\n",
            "### iteration step: 650 rmse: 0.016545251400206015\n",
            "### iteration step: 650 rmse: 0.016626249653981618\n",
            "### iteration step: 650 rmse: 0.01688643001680782\n",
            "### iteration step: 700 rmse: 0.016860404573811775\n",
            "### iteration step: 700 rmse: 0.0169608705553033\n",
            "### iteration step: 700 rmse: 0.016826602726679164\n",
            "### iteration step: 700 rmse: 0.016746432828981896\n",
            "### iteration step: 700 rmse: 0.016858446688334947\n",
            "### iteration step: 700 rmse: 0.01687540889151472\n",
            "### iteration step: 700 rmse: 0.016691366723842763\n",
            "### iteration step: 700 rmse: 0.016671613306581415\n",
            "### iteration step: 700 rmse: 0.016356841299460006\n",
            "### iteration step: 700 rmse: 0.016483701627880064\n",
            "### iteration step: 700 rmse: 0.016565782255103325\n",
            "### iteration step: 700 rmse: 0.01682595809387434\n",
            "### iteration step: 750 rmse: 0.016812234555127748\n",
            "### iteration step: 750 rmse: 0.016909810249468537\n",
            "### iteration step: 750 rmse: 0.01677434184450156\n",
            "### iteration step: 750 rmse: 0.01669564808037022\n",
            "### iteration step: 750 rmse: 0.016808034507313472\n",
            "### iteration step: 750 rmse: 0.016824200950734662\n",
            "### iteration step: 750 rmse: 0.016642204737009305\n",
            "### iteration step: 750 rmse: 0.016621953094516435\n",
            "### iteration step: 750 rmse: 0.016305314925454065\n",
            "### iteration step: 750 rmse: 0.016433172359986557\n",
            "### iteration step: 750 rmse: 0.01651606704620088\n",
            "### iteration step: 750 rmse: 0.0167761629468921\n",
            "### iteration step: 800 rmse: 0.01676857158858487\n",
            "### iteration step: 800 rmse: 0.016863781897757814\n",
            "### iteration step: 800 rmse: 0.016727261134303218\n",
            "### iteration step: 800 rmse: 0.01664988239092493\n",
            "### iteration step: 800 rmse: 0.01676260676079035\n",
            "### iteration step: 800 rmse: 0.016778182728572684\n",
            "### iteration step: 800 rmse: 0.01659777694424902\n",
            "### iteration step: 800 rmse: 0.016577088349542596\n",
            "### iteration step: 800 rmse: 0.016258962724825646\n",
            "### iteration step: 800 rmse: 0.0163876778083109\n",
            "### iteration step: 800 rmse: 0.01647123294707058\n",
            "### iteration step: 800 rmse: 0.016731125385411605\n",
            "### iteration step: 850 rmse: 0.01672646902886454\n",
            "### iteration step: 850 rmse: 0.01681973018240331\n",
            "### iteration step: 850 rmse: 0.016682239872119805\n",
            "### iteration step: 850 rmse: 0.016606086540773696\n",
            "### iteration step: 850 rmse: 0.016719129482484028\n",
            "### iteration step: 850 rmse: 0.016734248449789796\n",
            "### iteration step: 850 rmse: 0.01655510369474579\n",
            "### iteration step: 850 rmse: 0.016534024792447262\n",
            "### iteration step: 850 rmse: 0.016214694570497224\n",
            "### iteration step: 850 rmse: 0.016344186816629795\n",
            "### iteration step: 850 rmse: 0.016428314081843066\n",
            "### iteration step: 850 rmse: 0.016687864808158027\n",
            "### iteration step: 900 rmse: 0.016684522294856334\n",
            "### iteration step: 900 rmse: 0.016776167534416166\n",
            "### iteration step: 900 rmse: 0.016637754432690333\n",
            "### iteration step: 900 rmse: 0.016562776286994402\n",
            "### iteration step: 900 rmse: 0.01667612667253858\n",
            "### iteration step: 900 rmse: 0.016690877761128327\n",
            "### iteration step: 900 rmse: 0.01651275040955932\n",
            "### iteration step: 900 rmse: 0.016491317497517203\n",
            "### iteration step: 900 rmse: 0.016170999468386123\n",
            "### iteration step: 900 rmse: 0.016301221426625403\n",
            "### iteration step: 900 rmse: 0.016385869448168916\n",
            "### iteration step: 900 rmse: 0.016644943574669904\n",
            "### iteration step: 950 rmse: 0.016642135247517082\n",
            "### iteration step: 950 rmse: 0.01673243385410085\n",
            "### iteration step: 950 rmse: 0.01659312530882599\n",
            "### iteration step: 950 rmse: 0.01651929319425423\n",
            "### iteration step: 950 rmse: 0.01663294431422659\n",
            "### iteration step: 950 rmse: 0.01664738905536216\n",
            "### iteration step: 950 rmse: 0.016470094996700123\n",
            "### iteration step: 950 rmse: 0.016448336770160735\n",
            "### iteration step: 950 rmse: 0.016127200897529694\n",
            "### iteration step: 950 rmse: 0.016258123339566697\n",
            "### iteration step: 950 rmse: 0.01634326145454522\n",
            "### iteration step: 950 rmse: 0.016601736188367123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분해된 p,q 함수를 p*qT로 예측 행렬을 만들어 출력\n",
        "pred_matrix = np.dot(P,Q.T)\n",
        "print('예측 행렬: \\n', np.round(pred_matrix,3))"
      ],
      "metadata": {
        "id": "_0iIxC_VafoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2580dc3-3c98-4a2b-e0f6-2eb74b5b3051"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 행렬: \n",
            " [[3.99  0.804 1.334 2.002 1.714]\n",
            " [6.67  4.978 0.962 2.98  1.003]\n",
            " [6.843 0.408 2.987 3.977 3.986]\n",
            " [4.968 2.005 1.007 2.018 1.158]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> 널이 아닌 값은 비슷한 값으로, 널인 값은 새로운 예측값으로 채워짐"
      ],
      "metadata": {
        "id": "QoP-dKBoavbD"
      }
    }
  ]
}